========================
CODE SNIPPETS
========================
TITLE: Install Pydantic AI Examples Package
DESCRIPTION: Install the `pydantic-ai-examples` package by using the `examples` optional group. This allows for easy customization and running of Pydantic AI examples.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/install.md#_snippet_1

LANGUAGE: bash
CODE:
```
pip/uv-add "pydantic-ai[examples]"
```

----------------------------------------

TITLE: Run Pydantic AI Example with Zero Setup using uv and OpenAI
DESCRIPTION: Demonstrates a concise one-liner command using 'uv' to run a Pydantic AI example ('pydantic_model') by installing dependencies on the fly and setting the OpenAI API key directly, enabling quick testing.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/setup.md#_snippet_6

LANGUAGE: bash
CODE:
```
OPENAI_API_KEY='your-api-key' \
  uv run --with "pydantic-ai[examples]" \
  -m pydantic_ai_examples.pydantic_model
```

----------------------------------------

TITLE: Install Pydantic AI Examples Dependencies with pip or uv
DESCRIPTION: Demonstrates how to install the 'examples' optional dependency group for Pydantic AI using either 'pip' or 'uv' to enable running the provided examples.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/setup.md#_snippet_0

LANGUAGE: bash
CODE:
```
pip/uv-add "pydantic-ai[examples]"
```

----------------------------------------

TITLE: Run Pydantic AI example with default OpenAI model
DESCRIPTION: Instructions to execute the Pydantic AI example using the default `openai:gpt-4o` model. This command assumes dependencies are installed and environment variables are properly set as per the setup guide.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/pydantic-model.md#_snippet_0

LANGUAGE: bash
CODE:
```
python/uv-run -m pydantic_ai_examples.pydantic_model
```

----------------------------------------

TITLE: Run Question Graph Example via Command Line
DESCRIPTION: This command executes the question graph example. Ensure all necessary dependencies are installed and environment variables are configured as per the setup instructions before running.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/question-graph.md#_snippet_0

LANGUAGE: bash
CODE:
```
python/uv-run -m pydantic_ai_examples.question_graph
```

----------------------------------------

TITLE: Install Pydantic AI Examples Dependencies from Cloned Repo with uv
DESCRIPTION: Shows how to install extra dependencies for Pydantic AI examples when working from a cloned repository, specifically using the 'uv sync' command.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/setup.md#_snippet_1

LANGUAGE: bash
CODE:
```
uv sync --extra examples
```

----------------------------------------

TITLE: Install Pydantic AI Slim with Multiple Dependencies
DESCRIPTION: Install the 'slim' version of Pydantic AI with dependencies for multiple models or features by specifying a comma-separated list of optional groups, for example, `openai`, `vertexai`, and `logfire`.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/install.md#_snippet_3

LANGUAGE: bash
CODE:
```
pip/uv-add "pydantic-ai-slim[openai,vertexai,logfire]"
```

----------------------------------------

TITLE: Install Pydantic AI Dependencies and Pre-commit Hooks
DESCRIPTION: Command to install `pydantic-ai` itself, all its required dependencies, and set up the pre-commit hooks configured for the project. This command simplifies the initial setup process.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/contributing.md#_snippet_3

LANGUAGE: bash
CODE:
```
make install
```

----------------------------------------

TITLE: Install and Start Temporal Server Locally
DESCRIPTION: This shell script provides commands to install the Temporal CLI using Homebrew and start a local development Temporal server. This server is a prerequisite for running Temporal workflows and activities demonstrated in the Python example.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/temporal.md#_snippet_0

LANGUAGE: sh
CODE:
```
brew install temporal
temporal server start-dev
```

----------------------------------------

TITLE: Start Pydantic AI AG-UI Example Backend Server
DESCRIPTION: Initiates the Pydantic AI AG-UI example backend server. This command uses `uv-run` to execute the specified Python module, making the backend available for interaction.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/ag-ui.md#_snippet_1

LANGUAGE: bash
CODE:
```
python/uv-run -m pydantic_ai_examples.ag_ui
```

----------------------------------------

TITLE: Run Flight Booking Multi-Agent Example with Python
DESCRIPTION: This command executes the flight booking multi-agent example using Python. It assumes that all necessary dependencies are installed and environment variables are configured as per the setup instructions, allowing users to run the multi-agent flow.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/flight-booking.md#_snippet_1

LANGUAGE: bash
CODE:
```
python/uv-run -m pydantic_ai_examples.flight_booking
```

----------------------------------------

TITLE: Run Pydantic AI Examples via Module Execution
DESCRIPTION: Provides the general command to run any Pydantic AI example module using either 'python -m' or 'uv run -m', applicable whether Pydantic AI was installed or cloned.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/setup.md#_snippet_4

LANGUAGE: bash
CODE:
```
python/uv-run -m pydantic_ai_examples.<example_module_name>
```

----------------------------------------

TITLE: Run Pydantic AI Stream Markdown Example
DESCRIPTION: Execute the Pydantic AI example for streaming markdown output from an agent. This command assumes that all required dependencies are installed and environment variables for AI models (e.g., OpenAI, Google Gemini) are properly configured as per the setup instructions.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/stream-markdown.md#_snippet_0

LANGUAGE: Bash
CODE:
```
python/uv-run -m pydantic_ai_examples.stream_markdown
```

----------------------------------------

TITLE: Run Specific Pydantic AI Example: pydantic_model
DESCRIPTION: Shows how to execute the 'pydantic_model' example specifically, demonstrating the command structure for running individual Pydantic AI examples.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/setup.md#_snippet_5

LANGUAGE: bash
CODE:
```
python/uv-run -m pydantic_ai_examples.pydantic_model
```

----------------------------------------

TITLE: Install Pydantic AI Slim for OpenAI Model
DESCRIPTION: Perform a 'slim' installation of Pydantic AI to include only the dependencies required for a specific model, such as `OpenAIChatModel` from OpenAI, avoiding unnecessary packages.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/install.md#_snippet_2

LANGUAGE: bash
CODE:
```
pip/uv-add "pydantic-ai-slim[openai]"
```

----------------------------------------

TITLE: Copy Pydantic AI Examples to Local Directory
DESCRIPTION: Explains how to copy the Pydantic AI example files to a specified local directory for easier editing, customization, and local development.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/setup.md#_snippet_7

LANGUAGE: bash
CODE:
```
python/uv-run -m pydantic_ai_examples --copy-to examples/
```

----------------------------------------

TITLE: Install Pydantic AI Core Library
DESCRIPTION: Install the main `pydantic-ai` package, which includes core dependencies and libraries for all models. This installation requires Python 3.10+.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/install.md#_snippet_0

LANGUAGE: bash
CODE:
```
pip/uv-add pydantic-ai
```

----------------------------------------

TITLE: Install pre-commit Tool using uv
DESCRIPTION: Command to install the `pre-commit` tool using the `uv` package manager. Ensure `uv` version 0.4.30 or later is installed before running this command.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/contributing.md#_snippet_1

LANGUAGE: bash
CODE:
```
uv tool install pre-commit
```

----------------------------------------

TITLE: Initialize and Run a Basic Pydantic AI Agent
DESCRIPTION: This Python example demonstrates how to create a minimal Pydantic AI agent. It initializes an `Agent` instance with a specified model and static instructions, then runs a synchronous conversation with an LLM using `run_sync` and prints the generated output. This snippet requires the `pydantic_ai` package to be installed.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/README.md#_snippet_0

LANGUAGE: Python
CODE:
```
from pydantic_ai import Agent

# Define a very simple agent including the model to use, you can also set the model when running the agent.
agent = Agent(
    'anthropic:claude-sonnet-4-0',
    # Register static instructions using a keyword argument to the agent.
    # For more complex dynamically-generated instructions, see the example below.
    instructions='Be concise, reply with one sentence.',
)

# Run the agent synchronously, conducting a conversation with the LLM.
result = agent.run_sync('Where does "hello world" come from?')
print(result.output)
"""
The first known use of "hello, world" was in a 1974 textbook about the C programming language.
"""
```

----------------------------------------

TITLE: Install Deno Runtime via Shell Script
DESCRIPTION: Command to install the Deno runtime using a `curl` command that pipes to a shell script. This is one of the recommended installation methods for Deno.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/contributing.md#_snippet_2

LANGUAGE: bash
CODE:
```
curl -fsSL https://deno.land/install.sh | sh
```

----------------------------------------

TITLE: Clone AG-UI Repository for Frontend Setup
DESCRIPTION: Clones the official AG-UI repository from GitHub. This repository contains the `typescript-sdk` and the Dojo example frontend, which are necessary for running the AG-UI client.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/ag-ui.md#_snippet_2

LANGUAGE: shell
CODE:
```
git clone https://github.com/ag-ui-protocol/ag-ui.git
```

----------------------------------------

TITLE: Run Pydantic AI Whales Streaming Example
DESCRIPTION: Execute the Pydantic AI example script for streaming whale information. This command uses `python/uv-run` to launch the `stream_whales` module, assuming dependencies are installed and environment variables are configured as per the setup guide.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/stream-whales.md#_snippet_0

LANGUAGE: bash
CODE:
```
python/uv-run -m pydantic_ai_examples.stream_whales
```

----------------------------------------

TITLE: Install and Run clai globally using uv
DESCRIPTION: Install `clai` globally using `uv tool install` for persistent access across your system. After successful installation, run the `clai` command to start an interactive chat session with an AI model.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/clai/README.md#_snippet_2

LANGUAGE: bash
CODE:
```
uv tool install clai
```

LANGUAGE: bash
CODE:
```
clai
```

----------------------------------------

TITLE: Serve Documentation Locally
DESCRIPTION: Command to run the project's documentation page locally using `uv run mkdocs serve`. This allows contributors to preview documentation changes in real-time before committing them.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/contributing.md#_snippet_6

LANGUAGE: bash
CODE:
```
uv run mkdocs serve
```

----------------------------------------

TITLE: Run a Pydantic AI Agent with Claude Sonnet
DESCRIPTION: This snippet demonstrates how to initialize a Pydantic AI `Agent` with a specific LLM (Anthropic's Claude Sonnet 4.0) and static instructions. It then shows how to run the agent synchronously with a user prompt and print the LLM's output. The example highlights basic agent configuration and interaction with a large language model, assuming the `pydantic_ai` package is installed.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/index.md#_snippet_1

LANGUAGE: python
CODE:
```
from pydantic_ai import Agent

agent = Agent(  # (1)!
    'anthropic:claude-sonnet-4-0',
    instructions='Be concise, reply with one sentence.',  # (2)!
)

result = agent.run_sync('Where does "hello world" come from?')  # (3)!
print(result.output)
"""
The first known use of "hello, world" was in a 1974 textbook about the C programming language.
"""
```

----------------------------------------

TITLE: Install Pydantic AI AG-UI Dependencies
DESCRIPTION: Instructions for installing `pydantic-ai-slim` with the `ag-ui` extra and `uvicorn` using `pip` or `uv-add` for developing AG-UI agents.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/ag-ui.md#_snippet_0

LANGUAGE: bash
CODE:
```
pip/uv-add 'pydantic-ai-slim[ag-ui]'
```

LANGUAGE: bash
CODE:
```
pip/uv-add uvicorn
```

----------------------------------------

TITLE: Install pydantic-ai with Groq Support
DESCRIPTION: To enable Groq model usage, install either the full 'pydantic-ai' package or the 'pydantic-ai-slim' package with the 'groq' optional dependency group. This ensures all necessary components for Groq integration are available.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/groq.md#_snippet_0

LANGUAGE: bash
CODE:
```
pip/uv-add "pydantic-ai-slim[groq]"
```

----------------------------------------

TITLE: Initialize pydantic-ai Agent with Anthropic Model by name
DESCRIPTION: This example demonstrates how to initialize an `Agent` instance in `pydantic-ai` by directly referencing an Anthropic model using its prefixed name. This is a convenient way to quickly get started with a specific Anthropic model.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/anthropic.md#_snippet_2

LANGUAGE: python
CODE:
```
from pydantic_ai import Agent

agent = Agent('anthropic:claude-3-5-sonnet-latest')
...
```

----------------------------------------

TITLE: Install pydantic-ai with OpenAI Support
DESCRIPTION: Instructions to install the `pydantic-ai-slim` package with the `openai` optional group, which is required to use OpenAI models or OpenAI-compatible APIs.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/openai.md#_snippet_0

LANGUAGE: bash
CODE:
```
pip/uv-add "pydantic-ai-slim[openai]"
```

----------------------------------------

TITLE: Execute Pydantic AI SQL Generation Example
DESCRIPTION: Runs the Pydantic AI SQL generation example script using `uv-run`. This command executes the core functionality of generating SQL queries based on predefined inputs within the example.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/sql-gen.md#_snippet_1

LANGUAGE: bash
CODE:
```
python/uv-run -m pydantic_ai_examples.sql_gen
```

----------------------------------------

TITLE: Install Pydantic AI with MCP Support
DESCRIPTION: This snippet provides the command to install `pydantic-ai-slim` along with the necessary `mcp` optional group. This ensures that Pydantic AI has the required dependencies to act as an MCP client.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/mcp/client.md#_snippet_0

LANGUAGE: bash
CODE:
```
pip/uv-add "pydantic-ai-slim[mcp]"
```

----------------------------------------

TITLE: Install Pydantic AI with OpenTelemetry dependencies
DESCRIPTION: This command installs Pydantic AI with necessary OpenTelemetry SDK and OTLP exporter packages. It prepares the environment to run examples demonstrating direct OpenTelemetry integration without Logfire.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/logfire.md#_snippet_9

LANGUAGE: Text
CODE:
```
uv run \
  --with 'pydantic-ai-slim[openai]' \
  --with opentelemetry-sdk \
  --with opentelemetry-exporter-otlp \
  raw_otel.py
```

----------------------------------------

TITLE: Run Pydantic AI Agent with Sync, Async, and Streaming
DESCRIPTION: This Python example demonstrates how to interact with a Pydantic AI Agent using its `run_sync()`, `run()`, and `run_stream()` methods. It shows how to get a direct result from a synchronous call, await an asynchronous call, and stream text output from a context manager. The example queries an OpenAI GPT-4o agent for capital cities.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/agents.md#_snippet_1

LANGUAGE: Python
CODE:
```
from pydantic_ai import Agent

agent = Agent('openai:gpt-4o')

result_sync = agent.run_sync('What is the capital of Italy?')
print(result_sync.output)
#> The capital of Italy is Rome.


async def main():
    result = await agent.run('What is the capital of France?')
    print(result.output)
    #> The capital of France is Paris.

    async with agent.run_stream('What is the capital of the UK?') as response:
        async for text in response.stream_text():
            print(text)
            #> The capital of
            #> The capital of the UK is
            #> The capital of the UK is London.
```

----------------------------------------

TITLE: Run PostgreSQL Docker Container for SQL Generation Example
DESCRIPTION: Starts a transient PostgreSQL Docker container on port 54320 with a default password. This database is used to validate the SQL queries generated by the Pydantic AI example by running them as EXPLAIN queries.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/sql-gen.md#_snippet_0

LANGUAGE: bash
CODE:
```
docker run --rm -e POSTGRES_PASSWORD=postgres -p 54320:5432 postgres  # pragma: allowlist secret
```

----------------------------------------

TITLE: Install Pydantic AI Slim with Logfire support
DESCRIPTION: This command installs the slim version of `pydantic-ai` along with the `logfire` optional dependency. This is useful for environments where a minimal installation is preferred while still enabling Logfire integration.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/logfire.md#_snippet_1

LANGUAGE: bash
CODE:
```
pip/uv-add "pydantic-ai-slim[logfire]"
```

----------------------------------------

TITLE: Install Pydantic Evals Package
DESCRIPTION: Instructions for installing the `pydantic-evals` package, including an optional dependency for OpenTelemetry traces and Logfire integration.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/evals.md#_snippet_0

LANGUAGE: bash
CODE:
```
pip/uv-add pydantic-evals
```

LANGUAGE: bash
CODE:
```
pip/uv-add 'pydantic-evals[logfire]'
```

----------------------------------------

TITLE: Install Tavily Search Tool for Pydantic AI
DESCRIPTION: Instructions to install the `pydantic-ai-slim` package with the `tavily` optional group, which is required to use the Tavily search tool.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/common-tools.md#_snippet_2

LANGUAGE: bash
CODE:
```
pip/uv-add "pydantic-ai-slim[tavily]"
```

----------------------------------------

TITLE: Install Pydantic AI with FastA2A (A2A) Support
DESCRIPTION: This command installs the `pydantic-ai-slim` package along with its `a2a` extra, which automatically includes the FastA2A library. This is a convenient way to get both Pydantic AI and FastA2A set up for developing A2A-compliant AI agents. It simplifies dependency management for A2A integration.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/a2a.md#_snippet_2

LANGUAGE: bash
CODE:
```
pip/uv-add 'pydantic-ai-slim[a2a]'
```

----------------------------------------

TITLE: Integrate LangChain DuckDuckGoSearchRun Tool with Pydantic AI
DESCRIPTION: This example demonstrates how to use the `tool_from_langchain` convenience method to integrate a single LangChain tool, `DuckDuckGoSearchRun`, with a Pydantic AI agent. It shows how to initialize the tool, convert it for Pydantic AI, and then use it within an agent to perform a search query. This integration requires installing `langchain-community` and any packages specific to the LangChain tool (e.g., `ddgs`).

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/third-party-tools.md#_snippet_0

LANGUAGE: python
CODE:
```
from langchain_community.tools import DuckDuckGoSearchRun

from pydantic_ai import Agent
from pydantic_ai.ext.langchain import tool_from_langchain

search = DuckDuckGoSearchRun()
search_tool = tool_from_langchain(search)

agent = Agent(
    'google-gla:gemini-2.0-flash',
    tools=[search_tool],
)

result = agent.run_sync('What is the release date of Elden Ring Nightreign?')
print(result.output)
```

----------------------------------------

TITLE: Run Pydantic AI example with Gemini model
DESCRIPTION: Instructions to execute the Pydantic AI example, overriding the default model to use Google Gemini (e.g., `gemini-1.5-pro` or `gemini-1.5-flash`). This is achieved by setting the `PYDANTIC_AI_MODEL` environment variable before running the script.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/pydantic-model.md#_snippet_1

LANGUAGE: bash
CODE:
```
PYDANTIC_AI_MODEL=gemini-1.5-pro python/uv-run -m pydantic_ai_examples.pydantic_model
```

----------------------------------------

TITLE: Execute Pydantic AI SQL Generation Example with Custom Prompt
DESCRIPTION: Runs the Pydantic AI SQL generation example script, allowing a custom user prompt to be passed as an argument. This demonstrates the flexibility of the system in generating SQL queries based on dynamic user input.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/sql-gen.md#_snippet_2

LANGUAGE: bash
CODE:
```
python/uv-run -m pydantic_ai_examples.sql_gen "find me errors"
```

----------------------------------------

TITLE: Install Pydantic AI Slim with Google Dependencies
DESCRIPTION: Instructions to install the `pydantic-ai-slim` package with the `google` optional group using `pip` or `uv-add`. This provides the necessary dependencies for `GoogleModel`.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/google.md#_snippet_0

LANGUAGE: bash
CODE:
```
pip/uv-add "pydantic-ai-slim[google]"
```

----------------------------------------

TITLE: Install DuckDuckGo Search Tool for Pydantic AI
DESCRIPTION: Instructions to install the `pydantic-ai-slim` package with the `duckduckgo` optional group, which is required to use the DuckDuckGo search tool.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/common-tools.md#_snippet_0

LANGUAGE: bash
CODE:
```
pip/uv-add "pydantic-ai-slim[duckduckgo]"
```

----------------------------------------

TITLE: Install Pydantic-AI Slim with Mistral Support
DESCRIPTION: Instructions to install the `pydantic-ai-slim` package with the `mistral` optional group, which is required to use `MistralModel` and other Mistral-related functionalities.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/mistral.md#_snippet_0

LANGUAGE: bash
CODE:
```
pip/uv-add "pydantic-ai-slim[mistral]"
```

----------------------------------------

TITLE: Install Pydantic-AI with Hugging Face Dependencies
DESCRIPTION: This command installs the `pydantic-ai-slim` package along with its optional `huggingface` dependencies. This step is crucial for enabling `HuggingFaceModel` functionalities within your project. It ensures all necessary components for seamless Hugging Face integration are available.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/huggingface.md#_snippet_0

LANGUAGE: bash
CODE:
```
pip/uv-add "pydantic-ai-slim[huggingface]"
```

----------------------------------------

TITLE: Clone Pydantic AI Repository and Navigate
DESCRIPTION: Instructions to clone your forked Pydantic AI repository from GitHub and change the current directory into the newly cloned repository.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/contributing.md#_snippet_0

LANGUAGE: bash
CODE:
```
git clone git@github.com:<your username>/pydantic-ai.git
cd pydantic-ai
```

----------------------------------------

TITLE: Install pydantic-ai-slim with Anthropic support
DESCRIPTION: This command installs the `pydantic-ai-slim` package along with the necessary dependencies for Anthropic integration. It ensures that you have the required components to work with Anthropic models.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/anthropic.md#_snippet_0

LANGUAGE: bash
CODE:
```
pip/uv-add "pydantic-ai-slim[anthropic]"
```

----------------------------------------

TITLE: Install pydantic-ai-slim with Bedrock support
DESCRIPTION: Instructions on how to install the `pydantic-ai-slim` package with the `bedrock` optional group using pip or uv-add, which is required to use `BedrockConverseModel`.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/bedrock.md#_snippet_0

LANGUAGE: bash
CODE:
```
pip/uv-add "pydantic-ai-slim[bedrock]"
```

----------------------------------------

TITLE: Set up PostgreSQL with pgvector using Docker
DESCRIPTION: This command initializes a PostgreSQL container with the pgvector extension, mapping port 54320 to avoid conflicts and persisting data in a local `postgres-data` directory. This database serves as the vector store for the RAG example.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/rag.md#_snippet_0

LANGUAGE: bash
CODE:
```
mkdir postgres-data
docker run --rm \
  -e POSTGRES_PASSWORD=postgres \  # pragma: allowlist secret
  -p 54320:5432 \
  -v `pwd`/postgres-data:/var/lib/postgresql/data \
  pgvector/pgvector:pg17
```

----------------------------------------

TITLE: Install FastA2A Library for A2A Protocol in Python
DESCRIPTION: This command installs the `fasta2a` library, which provides an agentic framework-agnostic implementation of the A2A protocol in Python. It is available on PyPI and can be installed using `pip` or `uv-add`. FastA2A is built on Starlette and compatible with any ASGI server.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/a2a.md#_snippet_1

LANGUAGE: bash
CODE:
```
pip/uv-add fasta2a
```

----------------------------------------

TITLE: Set OpenAI API Key Environment Variable for Pydantic AI
DESCRIPTION: Illustrates how to set the 'OPENAI_API_KEY' environment variable, which is required for authenticating with OpenAI models when running Pydantic AI examples.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/setup.md#_snippet_2

LANGUAGE: bash
CODE:
```
export OPENAI_API_KEY=your-api-key
```

----------------------------------------

TITLE: Set Google Gemini API Key Environment Variable for Pydantic AI
DESCRIPTION: Illustrates how to set the 'GEMINI_API_KEY' environment variable, which is required for authenticating with Google Gemini models when running Pydantic AI examples.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/setup.md#_snippet_3

LANGUAGE: bash
CODE:
```
export GEMINI_API_KEY=your-api-key
```

----------------------------------------

TITLE: Install and Run clai globally using pip
DESCRIPTION: Install `clai` globally using `pip`, Python's standard package installer. Once installed, you can execute the `clai` command from your terminal to begin an interactive chat session with an AI model.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/clai/README.md#_snippet_3

LANGUAGE: bash
CODE:
```
pip install clai
```

LANGUAGE: bash
CODE:
```
clai
```

----------------------------------------

TITLE: Install Pydantic-AI with Cohere Support
DESCRIPTION: This command installs the 'pydantic-ai-slim' package along with the 'cohere' optional group, which provides the necessary dependencies for Cohere model integration.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/cohere.md#_snippet_0

LANGUAGE: bash
CODE:
```
pip/uv-add "pydantic-ai-slim[cohere]"
```

----------------------------------------

TITLE: Display Available Make Commands
DESCRIPTION: Command to view a list of all available `make` commands defined in the project's Makefile, along with their descriptions. This helps contributors understand the various development tasks that can be automated.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/contributing.md#_snippet_4

LANGUAGE: bash
CODE:
```
make help
```

----------------------------------------

TITLE: Query Pydantic AI RAG agent with a question
DESCRIPTION: This command demonstrates how to query the Pydantic AI RAG agent with a specific question after the search database has been built. It uses the `pydantic_ai_examples.rag` module to interact with the RAG system.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/rag.md#_snippet_2

LANGUAGE: bash
CODE:
```
python/uv-run -m pydantic_ai_examples.rag search "How do I configure logfire to work with FastAPI?"
```

----------------------------------------

TITLE: Run Pydantic AI CLI (`clai`)
DESCRIPTION: The `clai` CLI can be run using various methods, including `uvx`, `uv tool install`, or `pip install`. Running `clai` initiates an interactive session for chatting with the AI model.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/cli.md#_snippet_1

LANGUAGE: bash
CODE:
```
uvx clai
```

LANGUAGE: bash
CODE:
```
uv tool install clai
...
clai
```

LANGUAGE: bash
CODE:
```
pip install clai
...
clai
```

----------------------------------------

TITLE: Use DuckDuckGo Search Tool with Pydantic AI Agent
DESCRIPTION: Example demonstrating how to initialize a Pydantic AI Agent with the `duckduckgo_search_tool` and use it to perform a web search, then print the agent's output.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/common-tools.md#_snippet_1

LANGUAGE: python
CODE:
```
from pydantic_ai import Agent
from pydantic_ai.common_tools.duckduckgo import duckduckgo_search_tool

agent = Agent(
    'openai:o3-mini',
    tools=[duckduckgo_search_tool()],
    system_prompt='Search DuckDuckGo for the given query and return the results.',
)

result = agent.run_sync(
    'Can you list the top five highest-grossing animated films of 2025?'
)
print(result.output)
```

----------------------------------------

TITLE: Integrate ACI.dev TAVILY__SEARCH Tool with Pydantic AI
DESCRIPTION: This example demonstrates how to use the `tool_from_aci` convenience method to integrate a single ACI.dev tool, `TAVILY__SEARCH`, with a Pydantic AI agent. It shows how to initialize the tool by providing its name and a `linked_account_owner_id` (typically from an environment variable). This setup allows the agent to perform search queries using the ACI.dev tool, requiring the `aci-sdk` package and an `ACI_API_KEY` environment variable.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/third-party-tools.md#_snippet_2

LANGUAGE: python
CODE:
```
import os

from pydantic_ai import Agent
from pydantic_ai.ext.aci import tool_from_aci

tavily_search = tool_from_aci(
    'TAVILY__SEARCH',
    linked_account_owner_id=os.getenv('LINKED_ACCOUNT_OWNER_ID'),
)

agent = Agent(
    'google-gla:gemini-2.0-flash',
    tools=[tavily_search],
)

result = agent.run_sync('What is the release date of Elden Ring Nightreign?')
print(result.output)
```

----------------------------------------

TITLE: Implement a Durable Pydantic-AI Agent with Temporal Workflow
DESCRIPTION: This Python example demonstrates how to create a durable Pydantic-AI agent using `TemporalAgent` and integrate it into a Temporal workflow. It defines a `GeographyWorkflow` that utilizes the `TemporalAgent` to handle prompts, sets up a Temporal client, and starts a worker to execute the workflow. The code showcases connecting to a local Temporal server, registering necessary plugins for Pydantic-AI serialization and agent activities, and initiating a workflow execution.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/temporal.md#_snippet_1

LANGUAGE: python
CODE:
```
import uuid

from temporalio import workflow
from temporalio.client import Client
from temporalio.worker import Worker

from pydantic_ai import Agent
from pydantic_ai.durable_exec.temporal import (
    AgentPlugin,
    PydanticAIPlugin,
    TemporalAgent,
)

agent = Agent(
    'gpt-5',
    instructions="You're an expert in geography.",
    name='geography',  # (10)!
)

temporal_agent = TemporalAgent(agent)  # (1)!


@workflow.defn
class GeographyWorkflow:  # (2)!
    @workflow.run
    async def run(self, prompt: str) -> str:
        result = await temporal_agent.run(prompt)  # (3)!
        return result.output


async def main():
    client = await Client.connect(  # (4)!
        'localhost:7233',  # (5)!
        plugins=[PydanticAIPlugin()],  # (6)!
    )

    async with Worker(  # (7)!
        client,
        task_queue='geography',
        workflows=[GeographyWorkflow],
        plugins=[AgentPlugin(temporal_agent)],  # (8)!
    ):
        output = await client.execute_workflow(  # (9)!
            GeographyWorkflow.run,
            args=['What is the capital of Mexico?'],
            id=f'geography-{uuid.uuid4()}',
            task_queue='geography',
        )
        print(output)
        #> Mexico City (Ciudad de MÃ©xico, CDMX)
```

----------------------------------------

TITLE: Pydantic AI: Core Development and Utility Commands
DESCRIPTION: Provides a collection of `make` and `uv` commands for common development tasks within the Pydantic AI project. This includes installing dependencies, running code checks, executing tests, building documentation, and managing project dependencies.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/AGENTS.md#_snippet_0

LANGUAGE: Shell
CODE:
```
make install
```

LANGUAGE: Shell
CODE:
```
pre-commit run --all-files
```

LANGUAGE: Shell
CODE:
```
make test
```

LANGUAGE: Shell
CODE:
```
make docs
```

LANGUAGE: Shell
CODE:
```
make docs-serve
```

LANGUAGE: Shell
CODE:
```
uv run pytest tests/test_agent.py::test_function_name -v
```

LANGUAGE: Shell
CODE:
```
uv run pytest tests/test_agent.py -v
```

LANGUAGE: Shell
CODE:
```
uv run pytest tests/test_agent.py -v -s
```

LANGUAGE: Shell
CODE:
```
make sync
```

----------------------------------------

TITLE: Configure Pydantic AI Agent for Flexible Structured/Text Output
DESCRIPTION: This Python example demonstrates how to initialize a `pydantic-ai` `Agent` to accept either a structured Pydantic `Box` model or a plain string as output. It showcases the agent's ability to prompt for missing information (like units) and then successfully parse structured data when provided. The example also implicitly highlights the type checking considerations when using union or list types for `output_type`.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/output.md#_snippet_1

LANGUAGE: Python
CODE:
```
from pydantic import BaseModel

from pydantic_ai import Agent


class Box(BaseModel):
    width: int
    height: int
    depth: int
    units: str


agent = Agent(
    'openai:gpt-4o-mini',
    output_type=[Box, str], # (1)!
    system_prompt=(
        "Extract me the dimensions of a box, "
        "if you can't extract all data, ask the user to try again."
    ),
)

result = agent.run_sync('The box is 10x20x30')
print(result.output)
#> Please provide the units for the dimensions (e.g., cm, in, m).

result = agent.run_sync('The box is 10x20x30 cm')
print(result.output)
#> width=10 height=20 depth=30 units='cm'
```

----------------------------------------

TITLE: Install pydantic-graph library using pip or uv
DESCRIPTION: This command demonstrates how to install the `pydantic-graph` library using either `pip` or `uv` package managers. `pydantic-graph` is a required dependency for `pydantic-ai` and an optional one for `pydantic-ai-slim`.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_0

LANGUAGE: bash
CODE:
```
pip/uv-add pydantic-graph
```

----------------------------------------

TITLE: Question Graph State Diagram (Mermaid)
DESCRIPTION: This Mermaid diagram visualizes the state transitions within the question graph example. It illustrates the flow from asking a question, through answering and evaluation, to either congratulation or a retry.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/question-graph.md#_snippet_1

LANGUAGE: mermaid
CODE:
```
---
title: question_graph
---
stateDiagram-v2
  [*] --> Ask
  Ask --> Answer: ask the question
  Answer --> Evaluate: answer the question
  Evaluate --> Congratulate
  Evaluate --> Castigate
  Congratulate --> [*]: success
  Castigate --> Ask: try again
```

----------------------------------------

TITLE: Install Pydantic AI with pip or uv-add
DESCRIPTION: This command installs the core `pydantic-ai` package using either `pip` or `uv-add`, providing the necessary dependencies for building LLM applications.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/logfire.md#_snippet_0

LANGUAGE: bash
CODE:
```
pip/uv-add pydantic-ai
```

----------------------------------------

TITLE: Run AG-UI FastAPI Application with Uvicorn
DESCRIPTION: Command to start the FastAPI application, which exposes the Pydantic AI agent as an AG-UI server, using the Uvicorn ASGI server.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/ag-ui.md#_snippet_2

LANGUAGE: bash
CODE:
```
uvicorn run_ag_ui:app
```

----------------------------------------

TITLE: Build RAG search database for Pydantic AI
DESCRIPTION: This command builds the RAG search database by processing markdown documentation and generating embeddings. It requires the `OPENAI_API_KEY` environment variable and will make approximately 300 calls to the OpenAI embedding API.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/rag.md#_snippet_1

LANGUAGE: bash
CODE:
```
python/uv-run -m pydantic_ai_examples.rag build
```

----------------------------------------

TITLE: Configure AI Models with Provider-Specific Settings and Basic Fallback
DESCRIPTION: This snippet demonstrates how to configure `OpenAIChatModel` and `AnthropicModel` with provider-specific settings like temperature and max_tokens. It then shows how to combine these models using `FallbackModel` to enable automatic failover. The example concludes by running an agent with the fallback model and printing the output.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/overview.md#_snippet_2

LANGUAGE: python
CODE:
```
openai_model = OpenAIChatModel(
    'gpt-4o',
    settings=ModelSettings(temperature=0.7, max_tokens=1000)  # Higher creativity for OpenAI
)
anthropic_model = AnthropicModel(
    'claude-3-5-sonnet-latest',
    settings=ModelSettings(temperature=0.2, max_tokens=1000)  # Lower temperature for consistency
)

fallback_model = FallbackModel(openai_model, anthropic_model)
agent = Agent(fallback_model)

result = agent.run_sync('Write a creative story about space exploration')
print(result.output)
```

----------------------------------------

TITLE: Get Help for Pydantic AI CLI
DESCRIPTION: To view the available commands and options for the `clai` CLI, use the `--help` flag. This provides a comprehensive overview of its functionality.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/cli.md#_snippet_2

LANGUAGE: bash
CODE:
```
uvx clai --help
```

----------------------------------------

TITLE: Create a Streamable HTTP MCP Server
DESCRIPTION: This Python code demonstrates how to set up a basic MCP server using `FastMCP` that supports the Streamable HTTP transport. It defines a simple `add` tool and runs the server, which is a prerequisite for the client example.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/mcp/client.md#_snippet_1

LANGUAGE: python
CODE:
```
from mcp.server.fastmcp import FastMCP

app = FastMCP()

@app.tool()
def add(a: int, b: int) -> int:
    return a + b

if __name__ == '__main__':
    app.run(transport='streamable-http')
```

----------------------------------------

TITLE: Initialize Groq Model via Agent by Name
DESCRIPTION: This example shows the simplest way to use a Groq model with pydantic-ai. By providing a string identifier like 'groq:llama-3.3-70b-versatile' to the Agent constructor, pydantic-ai automatically configures and uses the specified Groq model.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/groq.md#_snippet_2

LANGUAGE: python
CODE:
```
from pydantic_ai import Agent

agent = Agent('groq:llama-3.3-70b-versatile')
...
```

----------------------------------------

TITLE: Conditionally Register Pydantic-AI Tool with `prepare` Method
DESCRIPTION: This example illustrates how to use the `prepare` method with a `pydantic-ai` tool to conditionally register it based on the `RunContext`. The `hitchhiker` tool is only included if the `deps` value in the context is `42`, demonstrating dynamic tool availability and how to return `None` from `prepare` to omit a tool.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/tools-advanced.md#_snippet_3

LANGUAGE: python
CODE:
```
from pydantic_ai import Agent, RunContext, ToolDefinition

agent = Agent('test')


async def only_if_42(
    ctx: RunContext[int], tool_def: ToolDefinition
) -> ToolDefinition | None:
    if ctx.deps == 42:
        return tool_def


@agent.tool(prepare=only_if_42)
def hitchhiker(ctx: RunContext[int], answer: str) -> str:
    return f'{ctx.deps} {answer}'


result = agent.run_sync('testing...', deps=41)
print(result.output)
result = agent.run_sync('testing...', deps=42)
print(result.output)
```

----------------------------------------

TITLE: Connect to MCP Server using Streamable HTTP Client
DESCRIPTION: This example illustrates how to create an `MCPServerStreamableHTTP` instance, register it with a Pydantic AI `Agent`, and use the agent to interact with the server. It shows how to define the server URL, attach it to an agent, and manage the connection using an `async with` context manager to run a prompt.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/mcp/client.md#_snippet_2

LANGUAGE: python
CODE:
```
from pydantic_ai import Agent
from pydantic_ai.mcp import MCPServerStreamableHTTP

server = MCPServerStreamableHTTP('http://localhost:8000/mcp') # (1) Define the MCP server with the URL used to connect.
agent = Agent('openai:gpt-4o', toolsets=[server]) # (2) Create an agent with the MCP server attached.

async def main():
    async with agent: # (3) Create a client session to connect to the server.
        result = await agent.run('What is 7 plus 5?')
    print(result.output)
    #> The answer is 12.
```

----------------------------------------

TITLE: Demonstrate Tool Schema Extraction with Pydantic AI
DESCRIPTION: This example illustrates how Pydantic AI automatically generates a JSON schema for a tool function by extracting parameters and their descriptions from the function signature and a Google-style docstring. It uses `FunctionModel` to print the generated schema, showcasing how parameter types and descriptions are incorporated.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/tools.md#_snippet_3

LANGUAGE: python
CODE:
```
from pydantic_ai import Agent
from pydantic_ai.messages import ModelMessage, ModelResponse, TextPart
from pydantic_ai.models.function import AgentInfo, FunctionModel

agent = Agent()


@agent.tool_plain(docstring_format='google', require_parameter_descriptions=True)
def foobar(a: int, b: str, c: dict[str, list[float]]) -> str:
    """Get me foobar.

    Args:
        a: apple pie
        b: banana cake
        c: carrot smoothie
    """
    return f'{a} {b} {c}'


def print_schema(messages: list[ModelMessage], info: AgentInfo) -> ModelResponse:
    tool = info.function_tools[0]
    print(tool.description)
    #>
    print(tool.parameters_json_schema)
    """
    {
        'additionalProperties': False,
        'properties': {
            'a': {'description': 'apple pie', 'type': 'integer'},
            'b': {'description': 'banana cake', 'type': 'string'},
            'c': {
                'additionalProperties': {'items': {'type': 'number'}, 'type': 'array'},
                'description': 'carrot smoothie',
                'type': 'object',
            },
        },
        'required': ['a', 'b', 'c'],
        'type': 'object',
    }
    """
    return ModelResponse(parts=[TextPart('foobar')])


agent.run_sync('hello', model=FunctionModel(print_schema))
```

----------------------------------------

TITLE: Connect to an MCP SSE server using Pydantic AI (Python)
DESCRIPTION: This example shows how to connect to an MCP server using the `MCPServerSSE` client in Pydantic AI. It initializes an `Agent` with the server and demonstrates how to run a query that utilizes a tool provided by the server. The `async with agent` block manages the client session.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/mcp/client.md#_snippet_5

LANGUAGE: Python
CODE:
```
from pydantic_ai import Agent
from pydantic_ai.mcp import MCPServerSSE

server = MCPServerSSE('http://localhost:3001/sse')  # (1)!
agent = Agent('openai:gpt-4o', toolsets=[server])  # (2)!


async def main():
    async with agent:  # (3)!
        result = await agent.run('What is 7 plus 5?')
    print(result.output)
    #> The answer is 12.
```

----------------------------------------

TITLE: Initialize GoogleModel with API Key for Generative Language API
DESCRIPTION: Example demonstrating how to initialize `GoogleModel` using an explicit `GoogleProvider` instance with an API key for accessing Gemini via the Generative Language API. This sets up an agent with the specified model.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/google.md#_snippet_2

LANGUAGE: python
CODE:
```
from pydantic_ai import Agent
from pydantic_ai.models.google import GoogleModel
from pydantic_ai.providers.google import GoogleProvider

provider = GoogleProvider(api_key='your-api-key')
model = GoogleModel('gemini-1.5-flash', provider=provider)
agent = Agent(model)
...
```

----------------------------------------

TITLE: Configuring Web Search Tool with Pydantic AI
DESCRIPTION: Illustrates how to configure the `WebSearchTool` with various parameters like `search_context_size`, `user_location` (including city, country, region, timezone), `blocked_domains`, `allowed_domains`, and `max_uses` for an Anthropic agent. This example shows how to customize web search behavior.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/builtin-tools.md#_snippet_1

LANGUAGE: python
CODE:
```
from pydantic_ai import Agent, WebSearchTool, WebSearchUserLocation

agent = Agent(
    'anthropic:claude-sonnet-4-0',
    builtin_tools=[
        WebSearchTool(
            search_context_size='high',
            user_location=WebSearchUserLocation(
                city='San Francisco',
                country='US',
                region='CA',
                timezone='America/Los_Angeles',
            ),
            blocked_domains=['example.com', 'spam-site.net'],
            allowed_domains=None,  # Cannot use both blocked_domains and allowed_domains with Anthropic
            max_uses=5,  # Anthropic only: limit tool usage
        )
    ],
)

result = agent.run_sync('Use the web to get the current time.')
# > In San Francisco, it's 8:21:41 pm PDT on Wednesday, August 6, 2025.
```

----------------------------------------

TITLE: Example of Pydantic AI Output Functions with Agent Chaining
DESCRIPTION: This comprehensive example demonstrates the use of Pydantic AI's output functions. It defines a `run_sql_query` function as an output type for a `sql_agent`, handling SQL parsing, table lookups, and `ModelRetry` for invalid queries. It also shows how to chain agents by having a `router_agent` hand off natural language queries to the `sql_agent`, managing potential failures and retries across agents.

SOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/output.md#_snippet_3

LANGUAGE: python
CODE:
```
import re

from pydantic import BaseModel

from pydantic_ai import Agent, ModelRetry, RunContext, UnexpectedModelBehavior


class Row(BaseModel):
    name: str
    country: str


tables = {
    'capital_cities': [
        Row(name='Amsterdam', country='Netherlands'),
        Row(name='Mexico City', country='Mexico'),
    ]
}


class SQLFailure(BaseModel):
    """An unrecoverable failure. Only use this when you can't change the query to make it work."""

    explanation: str


def run_sql_query(query: str) -> list[Row]:
    """Run a SQL query on the database."""

    select_table = re.match(r'SELECT (.+) FROM (\w+)', query)
    if select_table:
        column_names = select_table.group(1)
        if column_names != '*':
            raise ModelRetry("Only 'SELECT *' is supported, you'll have to do column filtering manually.")

        table_name = select_table.group(2)
        if table_name not in tables:
            raise ModelRetry(
                f"Unknown table '{table_name}' in query '{query}'. Available tables: {', '.join(tables.keys())}."
            )

        return tables[table_name]

    raise ModelRetry(f"Unsupported query: '{query}'.")


sql_agent = Agent[None, list[Row] | SQLFailure](
    'openai:gpt-4o',
    output_type=[run_sql_query, SQLFailure],
    instructions='You are a SQL agent that can run SQL queries on a database.',
)


async def hand_off_to_sql_agent(ctx: RunContext, query: str) -> list[Row]:
    """I take natural language queries, turn them into SQL, and run them on a database."""

    # Drop the final message with the output tool call, as it shouldn't be passed on to the SQL agent
    messages = ctx.messages[:-1]
    try:
        result = await sql_agent.run(query, message_history=messages)
        output = result.output
        if isinstance(output, SQLFailure):
            raise ModelRetry(f'SQL agent failed: {output.explanation}')
        return output
    except UnexpectedModelBehavior as e:
        # Bubble up potentially retryable errors to the router agent
        if (cause := e.__cause__) and isinstance(cause, ModelRetry):
            raise ModelRetry(f'SQL agent failed: {cause.message}') from e
        else:
            raise


class RouterFailure(BaseModel):
    """Use me when no appropriate agent is found or the used agent failed."""

    explanation: str


r_agent = Agent[None, list[Row] | RouterFailure](
    'openai:gpt-4o',
    output_type=[hand_off_to_sql_agent, RouterFailure],
    instructions='You are a router to other agents. Never try to solve a problem yourself, just pass it on.',
)

result = r_agent.run_sync('Select the names and countries of all capitals')
print(result.output)
"""
[
    Row(name='Amsterdam', country='Netherlands'),
    Row(name='Mexico City', country='Mexico'),
]
"""

result = r_agent.run_sync('Select all pets')
print(repr(result.output))
"""
RouterFailure(explanation="The requested table 'pets' does not exist in the database. The only available table is 'capital_cities', which does not contain data about pets.")
"""

result = r_agent.run_sync('How do I fly from Amsterdam to Mexico City?')
print(repr(result.output))
"""
RouterFailure(explanation='I am not equipped to provide travel information, such as flights from Amsterdam to Mexico City.')
"""
```
