"""Storage service for file outputs generated by file formatter agents.

This module handles the filesystem operations for CSV, TSV, and JSON file outputs:
- Writing files to disk with validation
- Path resolution and security checks
- File retrieval for downloads
- Cleanup of temporary files

File Lifecycle:
1. Content written to temp/processing/
2. Validation (format, size)
3. Move to outputs/{date}/{session}/
4. Return path for database recording

Security Features:
- Path traversal prevention via UUID-based lookups
- File size limits (100 MB max)
- CSV/TSV formula injection detection
- JSON structure validation
"""

import hashlib
import json
import logging
import re
import shutil
from datetime import datetime, timezone
from pathlib import Path
from typing import Literal
from uuid import UUID

from src.config import get_file_output_storage_path

logger = logging.getLogger(__name__)

# Constants
MAX_FILE_SIZE_BYTES = 100 * 1024 * 1024  # 100 MB
VALID_FILE_TYPES = frozenset({"csv", "tsv", "json"})
TRACE_ID_PATTERN = re.compile(r"^[a-f0-9]{32}$")
DESCRIPTOR_PATTERN = re.compile(r"^[a-zA-Z0-9_-]{1,100}$")

# Formula injection characters for CSV/TSV (cells starting with these could execute formulas)
FORMULA_INJECTION_CHARS = frozenset({"=", "+", "-", "@"})


class FileOutputStorageError(Exception):
    """Base exception for file output storage errors."""

    pass


class FileValidationError(FileOutputStorageError):
    """Raised when file content or input fails validation."""

    pass


class PathSecurityError(FileOutputStorageError):
    """Raised when a path traversal or security violation is detected."""

    pass


class FileSizeError(FileOutputStorageError):
    """Raised when file exceeds size limits."""

    pass


class FileOutputStorageService:
    """Service for managing file output storage operations.

    Handles writing, validation, and retrieval of generated file outputs.
    All paths are validated to prevent traversal attacks.
    """

    def __init__(self, base_path: Path | None = None):
        """Initialize the storage service.

        Args:
            base_path: Override base storage path (for testing).
                      Defaults to config path.
        """
        self.base_path = base_path or get_file_output_storage_path()
        self.outputs_path = self.base_path / "outputs"
        self.temp_processing_path = self.base_path / "temp" / "processing"
        self.temp_failed_path = self.base_path / "temp" / "failed"

        # Ensure directories exist
        self._ensure_directories()

    def _ensure_directories(self) -> None:
        """Create required directories if they don't exist."""
        for path in [self.outputs_path, self.temp_processing_path, self.temp_failed_path]:
            path.mkdir(parents=True, exist_ok=True)

    def _validate_trace_id(self, trace_id: str) -> None:
        """Validate trace ID format (32-char hex)."""
        if not TRACE_ID_PATTERN.match(trace_id):
            raise FileValidationError(
                f"Invalid trace_id format: must be 32 lowercase hex characters, got '{trace_id}'"
            )

    def _validate_session_id(self, session_id: str) -> None:
        """Validate session ID is not empty and safe for path use."""
        if not session_id or not session_id.strip():
            raise FileValidationError("session_id cannot be empty")
        # Prevent path traversal in session_id
        if ".." in session_id or "/" in session_id or "\\" in session_id:
            raise PathSecurityError(
                f"Invalid session_id: contains path traversal characters"
            )

    def _validate_descriptor(self, descriptor: str) -> None:
        """Validate descriptor is alphanumeric with underscores/hyphens only."""
        if not DESCRIPTOR_PATTERN.match(descriptor):
            raise FileValidationError(
                f"Invalid descriptor: must be 1-100 alphanumeric/underscore/hyphen characters, got '{descriptor}'"
            )

    def _validate_file_type(self, file_type: str) -> None:
        """Validate file type is supported."""
        if file_type not in VALID_FILE_TYPES:
            raise FileValidationError(
                f"Invalid file_type: must be one of {VALID_FILE_TYPES}, got '{file_type}'"
            )

    def _validate_content_size(self, content: str | bytes) -> None:
        """Validate content doesn't exceed size limit."""
        if isinstance(content, str):
            size = len(content.encode("utf-8"))
        else:
            size = len(content)

        if size > MAX_FILE_SIZE_BYTES:
            raise FileSizeError(
                f"Content size ({size:,} bytes) exceeds maximum ({MAX_FILE_SIZE_BYTES:,} bytes)"
            )

    def _check_csv_tsv_injection(self, content: str) -> list[str]:
        """Check CSV/TSV content for potential formula injection.

        Returns list of warnings (non-fatal) for cells that start with formula characters.
        """
        warnings = []
        lines = content.split("\n")
        for line_num, line in enumerate(lines, 1):
            # Check each cell (split by comma for CSV-like, tab for TSV-like)
            for delimiter in [",", "\t"]:
                if delimiter in line:
                    cells = line.split(delimiter)
                    for cell_num, cell in enumerate(cells, 1):
                        cell_stripped = cell.strip().strip('"').strip("'")
                        if cell_stripped and cell_stripped[0] in FORMULA_INJECTION_CHARS:
                            warnings.append(
                                f"Line {line_num}, cell {cell_num}: potential formula injection (starts with '{cell_stripped[0]}')"
                            )
        return warnings

    def _validate_json_structure(self, content: str) -> None:
        """Validate JSON content is valid JSON."""
        try:
            json.loads(content)
        except json.JSONDecodeError as e:
            raise FileValidationError(f"Invalid JSON content: {e}")

    def _validate_content(
        self, content: str | bytes, file_type: str
    ) -> list[str]:
        """Validate file content based on type.

        Args:
            content: File content to validate
            file_type: One of 'csv', 'tsv', 'json'

        Returns:
            List of warning messages (non-fatal issues)

        Raises:
            FileValidationError: If content is invalid
            FileSizeError: If content exceeds size limit
        """
        self._validate_content_size(content)
        warnings = []

        # Convert bytes to string for text-based validation
        if isinstance(content, bytes):
            try:
                content_str = content.decode("utf-8")
            except UnicodeDecodeError as e:
                raise FileValidationError(f"Content is not valid UTF-8: {e}")
        else:
            content_str = content

        if file_type in ("csv", "tsv"):
            warnings.extend(self._check_csv_tsv_injection(content_str))
        elif file_type == "json":
            self._validate_json_structure(content_str)

        return warnings

    def _generate_filename(
        self, trace_id: str, descriptor: str, file_type: str
    ) -> str:
        """Generate filename following naming convention.

        Pattern: {trace_id}_{descriptor}_{timestamp}.{extension}
        """
        timestamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
        return f"{trace_id}_{descriptor}_{timestamp}.{file_type}"

    def _get_output_directory(self, session_id: str) -> Path:
        """Get output directory for a session, organized by date.

        Structure: outputs/{date}/{session_id}/
        """
        date_str = datetime.now(timezone.utc).strftime("%Y-%m-%d")
        return self.outputs_path / date_str / session_id

    def _compute_file_hash(self, content: bytes) -> str:
        """Compute SHA-256 hash of file content."""
        return hashlib.sha256(content).hexdigest()

    def _verify_path_within_base(self, path: Path) -> None:
        """Verify a resolved path is within the base storage directory.

        Raises:
            PathSecurityError: If path is outside base directory
        """
        try:
            resolved = path.resolve()
            base_resolved = self.base_path.resolve()
            # Use is_relative_to (Python 3.9+) to check containment
            if not resolved.is_relative_to(base_resolved):
                raise PathSecurityError(
                    f"Path traversal detected: {resolved} is outside {base_resolved}"
                )
        except ValueError as e:
            raise PathSecurityError(f"Invalid path: {e}")

    def save_output(
        self,
        trace_id: str,
        session_id: str,
        content: str | bytes,
        file_type: Literal["csv", "tsv", "json"],
        descriptor: str,
    ) -> tuple[Path, str, int, list[str]]:
        """Save file output to storage.

        File lifecycle:
        1. Write to temp/processing/
        2. Validate content
        3. Move to outputs/{date}/{session}/
        4. Return path info for database recording

        Args:
            trace_id: 32-char hex Langfuse trace ID
            session_id: Chat session identifier
            content: File content (string or bytes)
            file_type: One of 'csv', 'tsv', 'json'
            descriptor: Human-readable descriptor (e.g., 'gene_results')

        Returns:
            Tuple of (final_path, file_hash, file_size, warnings)

        Raises:
            FileValidationError: If inputs or content are invalid
            FileSizeError: If content exceeds size limit
            PathSecurityError: If path traversal detected
        """
        # Validate all inputs
        self._validate_trace_id(trace_id)
        self._validate_session_id(session_id)
        self._validate_file_type(file_type)
        self._validate_descriptor(descriptor)

        # Generate filename
        filename = self._generate_filename(trace_id, descriptor, file_type)

        # Prepare content as bytes
        if isinstance(content, str):
            content_bytes = content.encode("utf-8")
        else:
            content_bytes = content

        # Validate content (before writing to disk)
        warnings = self._validate_content(content, file_type)

        # Write to temp location first
        temp_file = self.temp_processing_path / filename
        self._verify_path_within_base(temp_file)

        try:
            temp_file.write_bytes(content_bytes)
            logger.debug('Wrote temp file: %s', temp_file)

            # Compute hash and size
            file_hash = self._compute_file_hash(content_bytes)
            file_size = len(content_bytes)

            # Create final output directory
            output_dir = self._get_output_directory(session_id)
            output_dir.mkdir(parents=True, exist_ok=True)

            # Move to final location
            final_path = output_dir / filename
            self._verify_path_within_base(final_path)

            shutil.move(str(temp_file), str(final_path))
            logger.info(
                f"Saved file output: {final_path} ({file_size:,} bytes, hash={file_hash[:16]}...)"
            )

            return final_path, file_hash, file_size, warnings

        except Exception as e:
            # On any error, move to failed directory for debugging
            if temp_file.exists():
                failed_file = self.temp_failed_path / filename
                try:
                    shutil.move(str(temp_file), str(failed_file))
                    logger.error('Moved failed file to: %s', failed_file)
                except Exception as cleanup_err:
                    logger.warning('Failed to move temp file to failed dir: %s', cleanup_err)
                    temp_file.unlink(missing_ok=True)
            raise

    def get_output_path(self, file_path: str) -> Path | None:
        """Get validated path to a stored file.

        Args:
            file_path: Relative path stored in database (relative to base_path)

        Returns:
            Absolute Path if file exists and is valid, None otherwise

        Note:
            This method validates the path is within the storage directory
            to prevent path traversal attacks.
        """
        if not file_path:
            return None

        # Construct full path
        full_path = self.base_path / file_path

        # Security check: verify path is within base directory
        try:
            self._verify_path_within_base(full_path)
        except PathSecurityError as e:
            logger.warning('Path security violation: %s', e)
            return None

        # Check file exists
        if not full_path.exists() or not full_path.is_file():
            logger.warning('File not found: %s', full_path)
            return None

        return full_path.resolve()

    def delete_output(self, file_path: str) -> bool:
        """Delete a stored file output.

        Args:
            file_path: Relative path stored in database (relative to base_path)

        Returns:
            True if file was deleted, False if not found or error
        """
        full_path = self.get_output_path(file_path)

        if full_path is None:
            return False

        try:
            full_path.unlink()
            logger.info('Deleted file output: %s', full_path)

            # Try to clean up empty parent directories (up to outputs/)
            parent = full_path.parent
            while parent != self.outputs_path:
                try:
                    parent.rmdir()  # Only succeeds if empty
                    logger.debug('Removed empty directory: %s', parent)
                    parent = parent.parent
                except OSError:
                    break  # Directory not empty or other error

            return True

        except Exception as e:
            logger.error('Error deleting file %s: %s', full_path, e)
            return False

    def get_relative_path(self, absolute_path: Path) -> str:
        """Convert absolute path to relative path for database storage.

        Args:
            absolute_path: Absolute path to file

        Returns:
            Path relative to base_path as string
        """
        return str(absolute_path.relative_to(self.base_path))

    def cleanup_temp_files(self, older_than_hours: int = 24) -> int:
        """Clean up old temporary files.

        Args:
            older_than_hours: Delete files older than this many hours

        Returns:
            Number of files deleted
        """
        deleted = 0
        cutoff = datetime.now(timezone.utc).timestamp() - (older_than_hours * 3600)

        for temp_dir in [self.temp_processing_path, self.temp_failed_path]:
            if not temp_dir.exists():
                continue

            for file_path in temp_dir.iterdir():
                if file_path.is_file() and file_path.stat().st_mtime < cutoff:
                    try:
                        file_path.unlink()
                        deleted += 1
                        logger.debug('Cleaned up temp file: %s', file_path)
                    except Exception as e:
                        logger.warning('Failed to delete temp file %s: %s', file_path, e)

        if deleted:
            logger.info('Cleaned up %s temp files older than %sh', deleted, older_than_hours)

        return deleted
